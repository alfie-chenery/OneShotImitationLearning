\chapter{Introduction}
\label{chap:introduction}

Robotic manipulation is a complicated problem in the field of robotics in which we want a robot to interact with and influence it's environment in a specific way to complete a task. This is much more complicated than simple robot locomotion, as we don't just want the robot to move and exist within in its environment, but instead we want the robot to have meaningful interactions with certain objects in the environment. These interactions may be complex involving many moving parts, or multiple individual objects entirely. Furthermore these interactions may be unpredictable, if the robot's actions are prone to failure, or if the robot is interacting with objects it has no prior knowledge of.\\

As currently described, this is not a particularly hard problem. One could spend a few hours hand crafting an exact set of instructions for the robot to complete, such that when run from start to finish the robot completes the task. However, this implementation is missing a crucial feature. \textbf{We want the robot to generalise to different environments}. What we mean by this is the robot should be able to complete the task even when the task is placed in a different environment. Specifically the robot should be able to analyse the state of the environment prior to or during the execution of the task and be able to adapt to this environment in order to complete the task.\\

Suppose we have a robot arm in which we can control the angle of each joint and an environment which contains a coffee mug. We could easily define the exact joint angles at each time step, such that when the robot executes these positions, it manages to pick up the mug. However, if we now change the environment, and move the mug to the side, then the robot is going to fail the task. It will follow the instructions as before, trying to pick up a mug that is no longer there. This control algorithm does not generalise to different environments, it is hard coded for one specific environment setup. We want a system which can sense the environment in some way, and change it's actions accordingly, making decisions based on the information from its sensors. For example seeing the mug has been moved to the side, and changing the joint angles such that it still manages to pick it up.\\

It is obvious that hard coding the instructions for every possible task set up is intractable. The general approach to solving such a problem involves trying to teach the robot an understanding of the underlying task itself. We wish for the robot to understand the innate meaning of what the task is and how to accomplish it, abstracting the task away from the specifics of the environment it is performed within. For example, we do not want to teach the robot \speech{How do I pick up \textbf{\textit{this}} mug?} We want to teach it \speech{What does it mean to pick up a mug?} and \speech{How do I know when I have picked up a mug?}. These success criteria questions are something we will refer back to when considering different algorithmic approaches in \refchap{chap:background}.\\

If the robot is able to comprehend this higher level notion of what it truly means to complete the task, without relying on environment specific information, then we have successfully extracted the task out from the environment. In this sense the task can be placed in any environment, and the concept of the task itself has not changed, the robot knows how to pick up a mug in whichever environment it is found in. The robot does not need to work out how to complete the task, it only needs to compute how to apply the already known task in this new unseen environment.

%TODO flesh out
\section{Contributions}
Existing solutions to this problem broadly fall into two categories: Some solutions offload the work of extracting environment agnostic task information to the engineers. This requires us to formalise the task in a complicated mathematical expression which can be applied to any environment. These types of systems are explored in \refsec{sec:reinforcement-learning}. Alternatively, engineers can directly generalise the task by presenting it in many different environments and showing the robot how to complete the task in each case. This however still multiplies the workload of engineers providing training data to the system. These types of solutions are explored in \refsec{sec:imitation-learning} \\
Some newer solutions attempt to alleviate this issue by capturing specialised additional information during training time which allows the task to easily generalise. This additional information is something which can be automatically collected with no extra effort from the engineers. The downside being that for the robot to understand and use this additional information requires very large amounts of computational power, often in the form of huge artificial intelligence models.\\

This paper however, manages to achieve a one-shot imitation learning system, with comparable performance to existing solutions, while operating under much tighter computational constraints. The solution presented in this paper successfully utilises existing works in the field of computer vision to drastically reduce the hardware requirements of running such a system.\\

In our system we also incorporate strategies from state of the art solutions to produce a system which can learn multiple independent tasks. The robot is able to identify which task to complete from its corpus of trained tasks, using only observations of the environment it finds itself in and no external input from a human. It can identify the task to complete by analysing the environment, and then executes this task in the specific test time environment. It achieves all of this with minimal pre-training, each learned task consisting of a single human provided demonstration combined with automatically collected data which facilitates the generalisation to novel environments. This data comes with no additional workload to the demonstrator.

\section{Ethical Considerations}
This project does not work directly with people or animals. However, there could be safety considerations if deploying to a physical robot arm. These potential safety concerns are a consequence of using any robot arm and are not specific to this project. As such normal safety protocol in remaining clear of the robot arm during operation would be sufficient.\\
There are no legal or licensing concerns with this project. All libraries used are open source and can be installed through the default Python package manager, pip.\\
A widely generalisable learning agent will be applicable to many scenarios and tasks, some of which may be malicious in nature. While it is possible that work from this project could be taken and misused to teach a robot morally questionable tasks, this is not the intended use or focus of this project.\\
Finally while this project does not directly focus on environmental issues, we should consider the energy used running the simulations and equipment. While this is a non-zero amount, it is for the purposes of research and well within reasonable limits. Furthermore, this paper specifically focuses on producing a robot learning algorithm with lower hardware requirements to run effectively. This allows our system to run on lower power and more efficient machines than previously possible. While this is undoubtedly a benefit of the solution presented in this paper, reducing the environmental impacts is not the focus of this paper.