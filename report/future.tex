\chapter{Future Work}
\label{chap:future}

The system designed in \refchap{chap:technical} forms a solid core concept which demonstrates the capabilities of classical algorithms to create a One-shot Imitation Learning agent without the overdependence on AI technologies. However, as with any project, there remains some aspects, currently unimplemented, which one could consider improvements to the design. These improvements are simply not the core focus of the project, and given time constraints, priorities had to be chosen.

\section{Multi-stage tasks}
We discussed multi-stage tasks in \refchap{chap:background} where we defined them as a task in which the object of interest changes throughout the execution of the task. When the object of interest changes we need to align the end effector relative to the new object of interest, as though this sub-task was the entire demonstration and we were starting the system from here.\\

It is clear from this description how the current system could be extended to accommodate multi-stage tasks. During a demonstration we would need to automatically capture a new environment context $\Sigma_n$ whenever the object of interest changes. We decided earlier that this occurs whenever the gripper state changes. Then during test time, we will align the end effector to compute $\tau' = f(\tau, \Sigma_1, \Sigma_1')$. After aligning we execute $\tau'$ until the moment the gripper state changes. At this point we capture a new live environment context $\Sigma_2'$. We would re-run the trajectory transfer phase, aligning the current live image with the next stage's demonstration environment context. $\tau'' = f(\tau, \Sigma_2, \Sigma_2')$. We make sure to start executing $\tau''$ from the key frame step we stopped at in $\tau'$. This system could repeat as many times as needed for a $n$-stage task.\\

The reason we elected not to implement this feature was because it does not improve the core concept of this project. Undoubtedly this feature would make the system more widely applicable. However, this feature is not fundamental to the idea described in this paper. The limited time on this project was better spent improving the accuracy of the keypoint matching algorithm by investigating outlier filtering. The fact that the entire design for this feature was adequately explained in the single above paragraph, shows that it is not an interesting problem to solve. It is merely a change to the specifics of the code, it is not an exploration of the concepts described in this paper. With more time this would definitely be a worth while feature to add. Alas given the time constraints of this project, sacrifices needed to be made.

\section{Segmentation map}
A potential method to improve the accuracy of our system is to incorporate a segmentation map. A segmentation map is an image where every pixel is assigned an ID number based on some categorisation. For our purposes this could be which object the pixel belongs to. The advantage that this offers us is to prune any keypoint matches between different objects. If a keypoint in the live image is at a pixel belonging to object 1 in the segmentation map, then it should not map to a keypoint in the demonstration image, unless that keypoint location also belongs to object 1. Note that the live and demonstration images each have their own segmentation map. This prevents erroneous keypoint matches to the wrong object, most commonly to some background noise objects. The Pybullet simulation provides a perfect segmentation map when a camera image is captured. This is already available to us and could be easily incorporated to the keypoint matching algorithm. However, this segmentation map is a result of working in a simulation. In order to deploy this system on a real world robot arm, we would need some other computer vision system to produce a segmentation map.\\

We have seen in \refsec{sec:noise-test} that the modified Kabsch-Umeyama algorithm is sensitive to inaccuracies in the keypoint matching. Removing matches which are categorically incorrect may reduce this sensitivity. However, in practice it is difficult to tell how many inaccurate keypoint matches actually match to completely different objects. As a result it is unclear how much of an improvement this would make to the system. We hypothesise that this change would allow us to remove a small number of obviously incorrect matches. This would make the system more accurate in computing the exact offset between the demonstration and live object. However, due to the seemingly low frequency of these incorrect object matches, it is unlikely that tasks outright fail as a result of a few mismatches. Therefore we hypothesise while this would reduce the end effector pose error, it would likely not lead to more tests passing. This is however only a hypothesis, and something which would be interesting to explore in future work.

\section{Pre-computed embeddings}
A small improvement to reduce the amortized memory requirements of this system would be to pre-compute the embeddings of each image and store these as part of the environment context. By doing this we only need to use the DINO vision transformer \cite{dino-paper} to embed the image once when the demonstration is recorded. This removes the need to use any artificial intelligence components during inference time. While this is nice in principal it trades off reducing runtime memory requirements with increasing long term storage requirements of each demonstration. This may or may not be preferable depending on how many demonstrations are saved for a particular agent. While pre-computing embeddings would be an easy change to the system, it has not been implemented because it simply does not provide any useful impact on the accuracy of the system.

\section{Non-AI image descriptor}
An arguably better change would be to remove the need for any Artificial Intelligence components at all. This would bring the project to its logical conclusion. Currently we use the DINO vision transformer \cite{dino-paper} to embed images into a vector which can be compared. It is therefore clear to see that we could exchange this with a classical algorithm to embed an image into a feature vector. One such algorithm is the \socalled{Histograms of Oriented Gradients} (HOG) \cite{hog-patent}. The design is very similar to SIFT descriptors (discussed in \refsec{sec:keypoint-algos}), except that it creates a representation of the entire image, not just the local area around a keypoint. HOG has been shown to be suitable in use for object detection \cite{hog-object} and pose estimation \cite{hog-hand}.\\

The reason this modification was not implemented is that it is a much larger change than it may initially seem. The DINO vision transformer has been specifically trained for semantic keypoint detection. As such the embeddings it produces encode some notion of the keypoints within an image. This is why images of different objects with similar interactive properties have similar embeddings (for example, a can and a bottle are both cylindrical objects). This is not a feature immediately available to us by using HOG. Furthermore, we want our embedding to encode just the type of objects within the scene, not their positions, since positional information is handled entirely within the trajectory transfer stage. This is not something HOG can directly achieve since it is a concatenation of smaller scale cells in the image. If an object has moved from one cell to another, the HOG descriptor will be different. As a result we would need to design a more complex comparison function, which can account for differences in HOG descriptors due to an object position. This function would need to be able to output a high similarity if the objects described by the HOG descriptor are similar, even if the overall HOG descriptors are quite different. While this is certainly achievable, it is quite a complex task which is not possible within the time constraints of this project.

\section{Further testing \& real world deployment}
The use of a simulation environment has limited the scope of the test suite used to evaluate this project. Creating more tests for the system is not a case of grabbing an interesting object off the shelf, and placing it randomly in the environment. Objects need to instead be modelled as a rigid 3D mesh. Since this is a difficult and time consuming process we find ourselves limited by the built in objects available in the software package.\\

It would be desirable to test over a larger test suite with more objects and poses, to more rigorously test the generalisability of our system. Furthermore, it remains unexplored how our system handles the \socalled{Sim-to-Real Gap}. There was sadly insufficient time to deploy this project onto a physical robot arm, and so we are left to speculate on how this would have affected the performance. Imperfections in objects and lighting changes would likely provide additional identifiable features on objects, potentially allowing the system to detect more keypoints than in simulation. However, there are a number of factors which become impossible to overlook when using a real world system. Issues such as camera calibration and imperfections in joint motor movements, would likely create new challenges for the system to overcome.